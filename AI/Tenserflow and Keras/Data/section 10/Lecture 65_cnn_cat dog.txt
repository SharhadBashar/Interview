############Work with real imagery data

import cv2
import numpy as np
import os      

from random import shuffle 
import tensorflow as tf
import matplotlib.pyplot as plt

from tqdm import tqdm   

import tflearn ##TFlearn is a modular and transparent deep learning library built on top of Tensorflow.

from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.estimator import regression

TRAIN_DIR = 'train'
#TEST_DIR = 'test'
IMG_SIZE = 50
LR = 1e-3
MODEL_NAME = 'dogs-vs-cats-convnet'

#########Labels for cats and dogs

def create_label(image_name):
    """ Create an one-hot encoded vector from image name """
    word_label = image_name.split('.')[-3]
    if word_label == 'cat':
        return np.array([1,0])
    elif word_label == 'dog':
        return np.array([0,1])

#######Pre-process training data

def create_train_data():
    training_data = []
    for img in tqdm(os.listdir(TRAIN_DIR)):
        path = os.path.join(TRAIN_DIR, img)
        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)#read in image as grey scale
        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))
        training_data.append([np.array(img_data), create_label(img)])
    shuffle(training_data)
    np.save('train_data.npy', training_data)
    return training_data

# If dataset is not created:
train_data = create_train_data()

## Resized our images to 50 x 50 x 1 
train = train_data[:-500]
test = train_data[-500:]
X_train = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)#50 x 50 x 1
y_train = [i[1] for i in train]
X_test = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y_test = [i[1] for i in test]

####### Use the in-built CNN functions

tf.reset_default_graph()
convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')

## a convolutional layer with 32 filters and stride = 5 is created. The activation function is ReLU. 
convnet = conv_2d(convnet, 32, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)## Pooling layer is created

## a convolutional layer with 64 filters and stride = 5 is created. The activation function is ReLU.
convnet = conv_2d(convnet, 64, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)## Pooling layer is created


convnet = fully_connected(convnet, 1024, activation='relu')#a fully-connected layer with 1024 neurons is added

convnet = dropout(convnet, 0.8)#a dropout layer with keep probability of 0.8 is used to finish our model.

convnet = fully_connected(convnet, 2, activation='softmax')

##use Adam as optimizer with learning rate set to 0.001. Our loss function is categorical cross entropy.
convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')

##Deep Neural Net for 10 epochs.
model = tflearn.DNN(convnet, tensorboard_dir='log', tensorboard_verbose=0)

model.fit({'input': X_train}, {'targets': y_train}, n_epoch=10, 
          validation_set=({'input': X_test}, {'targets': y_test}), 
          snapshot_step=500, show_metric=True, run_id=MODEL_NAME)
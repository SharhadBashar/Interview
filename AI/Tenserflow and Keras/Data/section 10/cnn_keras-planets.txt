

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt

import math

from sklearn.preprocessing import MinMaxScaler

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, Dropout, Flatten
from keras.layers.normalization import BatchNormalization
from keras.optimizers import Adam
from keras.callbacks import LearningRateScheduler
from keras.regularizers import l2, l1

data = pd.read_json('planesnet.json')
data

##preprocessing

x = []
for d in data['data']:
    d = np.array(d)
    x.append(d.reshape(( 3, 20 * 20)).T.reshape( (20,20,3) ))#3 colour channel- rgb 
x = np.array(x)
y = np.array(data['labels'])#response
print(x.shape)
print(y.shape)

# splitting the data into training ans test sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)

##normalize

scalar = MinMaxScaler()
scalar.fit(x_train.reshape(x_train.shape[0],-1))
x_train = scalar.transform(x_train.reshape(x_train.shape[0], -1)).reshape(x_train.shape)
x_test = scalar.transform(x_test.reshape(x_test.shape[0], -1)).reshape(x_test.shape)

## CNN model

def create_cnn(data_shape):

    kernel_size = 3
    
    model = Sequential()

    model.add(Conv2D(16, (kernel_size), strides=(1,1), padding='valid',input_shape=(data_shape[1], data_shape[2], data_shape[3])))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
#     model.add(MaxPooling2D((2,2)))


    model.add(Conv2D(32, (kernel_size), strides=(1,1), padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
#     model.add(MaxPooling2D((2,2)))

    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
#     model.add(MaxPooling2D((2,2)))

    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D((2,2)))

    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D((2,2)))
    
    model.add(Flatten())
#     model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))

    model.add(Dense(1, activation='sigmoid'))

    return model

model = create_cnn(x_train.shape)
print(model.summary())

def step_decay(epoch):
    initial_lrate = 0.0001
    drop = 0.5
    epochs_drop = 10.0
    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
#    if epoch:
#        lrate = initial_lrate/np.sqrt(epoch)
#    else:
#        return initial_lrate
    return lrate
opt = Adam(lr=0.0001)
lrate = LearningRateScheduler(step_decay)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])
history = model.fit(x_train, y_train, batch_size=64, epochs=50, shuffle=True, verbose=2 ,
                               validation_data=(x_test, y_test), callbacks=[lrate],
                               )